{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8adKFQS7E-"
      },
      "source": [
        "# **Лабораторна робота 6: Пошук аномалій та вирішення задачі *anomaly detection* за допомогою бібліотек `scikit-learn`та `PyTorch`**\n",
        "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
        "\n",
        "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvneQUbQRRqZ"
      },
      "source": [
        "### Мета роботи:\n",
        "Ознайомитися з основними методами виявлення аномалій, навчитися використовувати бібліотеки `scikit-learn` та `PyTorch` для реалізації алгоритмів пошуку аномалій, проаналізувати ефективність різних методів на реальних наборах даних з Kaggle.\n",
        "\n",
        "\n",
        "### Опис завдання:\n",
        "\n",
        "1. **Постановка задачі**:\n",
        "   Використовуючи один із доступних наборів даних Kaggle (наприклад, *Credit Card Fraud Detection*, *Network Intrusion*, або інші), вам потрібно розв'язати задачу виявлення аномалій. Основна мета — ідентифікувати аномальні записи серед нормальних. Вибраний набір даних повинен містити мітки аномалій для перевірки результатів.\n",
        "\n",
        "2. **Етапи виконання завдання**:\n",
        "   - Завантажте та підготуйте набір даних.\n",
        "   - Проведіть попередню обробку даних (масштабування, заповнення пропущених значень, видалення нерелевантних ознак).\n",
        "   - Використайте різні методи виявлення аномалій:\n",
        "     - **Методи з бібліотеки scikit-learn**:\n",
        "       - Isolation Forest\n",
        "       - One-Class SVM\n",
        "       - Local Outlier Factor (LOF)\n",
        "     - **Методи з використанням PyTorch**:\n",
        "       - Автоенкодери для виявлення аномалій.\n",
        "   - Порівняйте отримані результати, обчисліть метрики якості (Precision, Recall, F1-Score).\n",
        "   - Оцініть, який метод найкраще підходить для вирішення задачі на вашому наборі даних.\n",
        "\n",
        "### Покрокова інструкція\n",
        "\n",
        "1. **Підготовка середовища**:\n",
        "   - Встановіть необхідні бібліотеки:\n",
        "     ```\n",
        "     pip install scikit-learn torch pandas numpy matplotlib\n",
        "     ```\n",
        "\n",
        "2. **Вибір набору даних з Kaggle**:\n",
        "   Зареєструйтесь на Kaggle та оберіть один із наборів даних для виявлення аномалій. Наприклад:\n",
        "   - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
        "   - [Network Intrusion Detection](https://www.kaggle.com/xyuanh/benchmarking-datasets)\n",
        "\n",
        "3. **Попередня обробка даних**:\n",
        "   - Завантажте дані та проведіть їхню початкову обробку.\n",
        "   - Масштабуйте ознаки за допомогою `StandardScaler` або `MinMaxScaler`.\n",
        "   - Розділіть дані на навчальну і тестову вибірки.\n",
        "\n",
        "4. **Методи з бібліотеки `scikit-learn`**:\n",
        "\n",
        "   - **Isolation Forest**:\n",
        "     ```\n",
        "     from sklearn.ensemble import IsolationForest\n",
        "     ```\n",
        "\n",
        "   - **One-Class SVM**:\n",
        "     ```\n",
        "     from sklearn.svm import OneClassSVM\n",
        "     ```\n",
        "\n",
        "   - **Local Outlier Factor**:\n",
        "     ```\n",
        "     from sklearn.neighbors import LocalOutlierFactor\n",
        "     ```\n",
        "\n",
        "5. **Методи на основі нейронних мереж (PyTorch)**:\n",
        "\n",
        "   Використайте автоенкодер для пошуку аномалій. Побудуйте нейронну мережу з енкодером і декодером. Під час навчання порівняйте відновлені дані з вхідними та обчисліть помилку. Записи з великою помилкою можуть бути аномаліями.\n",
        "\n",
        "   - **Реалізація автоенкодера**:\n",
        "     ```\n",
        "     import torch\n",
        "     import torch.nn as nn\n",
        "     import torch.optim as optim\n",
        "     ```\n",
        "\n",
        "6. **Оцінка результатів**:\n",
        "   Використовуйте метрики оцінки якості:\n",
        "   - `Precision`, `Recall`, `F1-score`\n",
        "   ```\n",
        "   from sklearn.metrics import classification_report\n",
        "   ```\n",
        "\n",
        "7. **Звіт**:\n",
        "   - Поясніть, який метод дав найкращі результати.\n",
        "   - Проаналізуйте, чому деякі методи працюють краще на вашому наборі даних.\n",
        "   - Оцініть можливості використання глибоких нейронних мереж (автоенкодерів) для вирішення задачі.\n",
        "\n",
        "\n",
        "### Результати, які необхідно надати:\n",
        "1. Код рішення у вигляді Jupyter Notebook з аналізом результатів та поясненнями.\n",
        "\n",
        "\n",
        "### Дедлайн:\n",
        "[23 жовтня 23:59]\n",
        "\n",
        "\n",
        "### Корисні ресурси:\n",
        "- [Документація PyTorch](https://pytorch.org/docs/stable/index.html)\n",
        "- [Документація scikit-learn](https://scikit-learn.org/stable/documentation.html)\n",
        "- [Kaggle Datasets](https://www.kaggle.com/datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NeqgMqm2UETO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('creditcard.csv')\n",
        "\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data[['scaled_amount', 'scaled_time']] = scaler.fit_transform(data[['Amount', 'Time']])\n",
        "data = data.drop(['Amount', 'Time'], axis=1)\n",
        "\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Isolation Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.35      0.24      0.29        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.68      0.62      0.64     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "isolation_forest = IsolationForest(contamination=0.001, random_state=42)\n",
        "y_pred_train = isolation_forest.fit_predict(X_train)\n",
        "y_pred_test = isolation_forest.predict(X_test)\n",
        "\n",
        "y_pred_test = [1 if x == -1 else 0 for x in y_pred_test]\n",
        "\n",
        "print(\"Isolation Forest:\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Class SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56864\n",
            "           1       0.07      0.41      0.12        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.53      0.70      0.56     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "oc_svm = OneClassSVM(gamma='auto', nu=0.001)\n",
        "oc_svm.fit(X_train)\n",
        "\n",
        "y_pred_svm = oc_svm.predict(X_test)\n",
        "y_pred_svm = [1 if x == -1 else 0 for x in y_pred_svm]\n",
        "\n",
        "print(\"One-Class SVM:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local Outlier Factor:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.04      0.02      0.03        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.52      0.51      0.51     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.001)\n",
        "y_pred_lof = lof.fit_predict(X_test)\n",
        "y_pred_lof = [1 if x == -1 else 0 for x in y_pred_lof]\n",
        "\n",
        "print(\"Local Outlier Factor:\")\n",
        "print(classification_report(y_test, y_pred_lof))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(X_train.shape[1], 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(8, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, X_train.shape[1])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "model = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.1014\n",
            "Epoch 2, Loss: 1.1003\n",
            "Epoch 3, Loss: 1.0993\n",
            "Epoch 4, Loss: 1.0983\n",
            "Epoch 5, Loss: 1.0974\n",
            "Epoch 6, Loss: 1.0965\n",
            "Epoch 7, Loss: 1.0957\n",
            "Epoch 8, Loss: 1.0948\n",
            "Epoch 9, Loss: 1.0940\n",
            "Epoch 10, Loss: 1.0932\n",
            "Epoch 11, Loss: 1.0924\n",
            "Epoch 12, Loss: 1.0916\n",
            "Epoch 13, Loss: 1.0908\n",
            "Epoch 14, Loss: 1.0900\n",
            "Epoch 15, Loss: 1.0892\n",
            "Epoch 16, Loss: 1.0883\n",
            "Epoch 17, Loss: 1.0874\n",
            "Epoch 18, Loss: 1.0864\n",
            "Epoch 19, Loss: 1.0854\n",
            "Epoch 20, Loss: 1.0844\n"
          ]
        }
      ],
      "source": [
        "X_train_tensor = torch.FloatTensor(X_train.values)\n",
        "X_test_tensor = torch.FloatTensor(X_test.values)\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, X_train_tensor)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autoencoder:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56864\n",
            "           1       0.10      0.56      0.16        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.55      0.78      0.58     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructions = model(X_test_tensor)\n",
        "    loss = torch.mean((reconstructions - X_test_tensor) ** 2, dim=1)\n",
        "\n",
        "threshold = torch.quantile(loss, 0.99).item()\n",
        "y_pred_autoencoder = (loss > threshold).int().numpy()\n",
        "\n",
        "print(\"Autoencoder:\")\n",
        "print(classification_report(y_test, y_pred_autoencoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for each method:\n",
            "Isolation Forest: Precision=0.0965, Recall=0.5612, F1-Score=0.1647\n",
            "One-Class SVM: Precision=0.0677, Recall=0.4082, F1-Score=0.1161\n",
            "LOF: Precision=0.0351, Recall=0.0204, F1-Score=0.0258\n",
            "Autoencoder: Precision=0.0965, Recall=0.5612, F1-Score=0.1647\n"
          ]
        }
      ],
      "source": [
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "methods = ['Isolation Forest', 'One-Class SVM', 'LOF', 'Autoencoder']\n",
        "predictions = [y_pred_test, y_pred_svm, y_pred_lof, y_pred_autoencoder]\n",
        "\n",
        "for y_pred in predictions:\n",
        "    precision_scores.append(precision_score(y_test, y_pred, zero_division=0))\n",
        "    recall_scores.append(recall_score(y_test, y_pred, zero_division=0))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "print(\"Metrics for each method:\")\n",
        "for i, method in enumerate(methods):\n",
        "    print(f\"{method}: Precision={precision_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, F1-Score={f1_scores[i]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Висновок:**\n",
        "\n",
        "1. Найкращий метод: Isolation Forest показав найкращі результати з Precision 0.35, Recall 0.24 та F1-Score 0.29. Він досяг балансу між точністю та здатністю виявляти аномалії, хоча результати все ще далекі від ідеальних.\n",
        "\n",
        "2. Причина кращої роботи деяких методів:\n",
        "   - Isolation Forest гарно виявляє аномалії в даних і не вимагає нормального розподілу даних.\n",
        "   - One-Class SVM має високий Recall (0.41), але низький Precision (0.07), що вказує на багато хибних спрацювань.\n",
        "   - Local Outlier Factor (LOF) не так добре працює на великих наборах даних.\n",
        "   \n",
        "3. Оцінка використання автоенкодерів: Автоенкодер досяг Recall 0.56 (краще, ніж інші методи), але має низький \n",
        "Precision 0.10, що свідчить про багато хибних спрацювань.\n",
        "\n",
        "Загальний висновок: Isolation Forest є найбільш збалансованим методом для цього завдання, але якщо важливо не пропускати аномалії, автоенкодер також може бути корисним."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
